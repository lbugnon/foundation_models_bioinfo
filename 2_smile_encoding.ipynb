{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "uFppw19BNeRz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37167a7c32e74b50a19898ae2ebaf9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b361ff818c44e509d4e56f682df7051",
              "IPY_MODEL_d2f9ca6e09384bc9a0d68cc4b872e72d",
              "IPY_MODEL_ea2db7f24aee41ec88facccb8f620db3"
            ],
            "layout": "IPY_MODEL_6c4a16ec1110442e8f6c4d9c4797d80f"
          }
        },
        "3b361ff818c44e509d4e56f682df7051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5fc5a70a0142018febbae0bf50430e",
            "placeholder": "​",
            "style": "IPY_MODEL_479a8821a0264da5b8d721863c8ab500",
            "value": "config.json: 100%"
          }
        },
        "d2f9ca6e09384bc9a0d68cc4b872e72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36b67bed1c8441aa6626002ef622090",
            "max": 573,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3052c02b67694a1694e6983b49214b32",
            "value": 573
          }
        },
        "ea2db7f24aee41ec88facccb8f620db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dee781d1a824550b4d447cac93dddfd",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8e1f25281f4ca8a3fe6b3e1de3a538",
            "value": " 573/573 [00:00&lt;00:00, 8.72kB/s]"
          }
        },
        "6c4a16ec1110442e8f6c4d9c4797d80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5fc5a70a0142018febbae0bf50430e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479a8821a0264da5b8d721863c8ab500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c36b67bed1c8441aa6626002ef622090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3052c02b67694a1694e6983b49214b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dee781d1a824550b4d447cac93dddfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8e1f25281f4ca8a3fe6b3e1de3a538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf47037ace9440094e73c356a5ab9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e6bcc0697ae412c9aab1bb0938dc72a",
              "IPY_MODEL_34650e862d75435c83984c974f7738e5",
              "IPY_MODEL_8ba2dc5284aa4cf9802b9e8716230af9"
            ],
            "layout": "IPY_MODEL_97f54dde25934491b6a0f0331db16090"
          }
        },
        "0e6bcc0697ae412c9aab1bb0938dc72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef268fd44f484c7da7cea2ab24a759c5",
            "placeholder": "​",
            "style": "IPY_MODEL_a210242468b641c1912e5a45e81e7ccd",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "34650e862d75435c83984c974f7738e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f58deb079a41ed8d12b0dc61a555d3",
            "max": 174524210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a83da9abeb34d499f4551a8220a3977",
            "value": 174524210
          }
        },
        "8ba2dc5284aa4cf9802b9e8716230af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52553d4ead424f15a4b47406b1f29519",
            "placeholder": "​",
            "style": "IPY_MODEL_04e9e70348024ac3a0a7b87bf8827a93",
            "value": " 175M/175M [00:04&lt;00:00, 42.5MB/s]"
          }
        },
        "97f54dde25934491b6a0f0331db16090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef268fd44f484c7da7cea2ab24a759c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a210242468b641c1912e5a45e81e7ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f58deb079a41ed8d12b0dc61a555d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a83da9abeb34d499f4551a8220a3977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52553d4ead424f15a4b47406b1f29519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e9e70348024ac3a0a7b87bf8827a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained model. Training dataset was 23M sequences from PubChem + SureChEMBL + SmProt + RandPept.\n",
        "\n",
        "More details and training scripts:\n",
        "- https://www.biorxiv.org/content/10.1101/2024.08.09.607221v1\n",
        "- https://github.com/AaronFeller/PeptideCLM/"
      ],
      "metadata": {
        "id": "7_pFygMGgeOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"https://github.com/lbugnon/foundation_models_bioinfo/raw/refs/heads/main/data/\"\n",
        "smiles = pd.read_csv(f\"{path}smiles_pampa.csv\")\n",
        "smiles.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfcRfzacg2GC",
        "outputId": "509c2380-28c3-41f3-8161-1595d0f4cb7d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5333, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles.PAMPA.hist(bins=100);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "lnRp5x4BvYvs",
        "outputId": "752a46d0-39a9-4898-aaab-581eef966de1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "SMILES ad-hoc tokenizer"
      ],
      "metadata": {
        "id": "uFppw19BNeRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SmilesPE datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hgzSpI5OOGN",
        "outputId": "1b4d6917-2442-4091-e67d-13f608d4632b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SmilesPE\n",
            "  Downloading SmilesPE-0.0.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.10/dist-packages (from SmilesPE) (1.0.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from SmilesPE) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->SmilesPE) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->SmilesPE) (7.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->SmilesPE) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading SmilesPE-0.0.3-py3-none-any.whl (15 kB)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, SmilesPE, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SmilesPE-0.0.3 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import codecs\n",
        "import unicodedata\n",
        "from typing import List, Optional\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
        "    vocab = collections.OrderedDict()\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "        tokens = reader.readlines()\n",
        "    for index, token in enumerate(tokens):\n",
        "        token = token.rstrip(\"\\n\")\n",
        "        vocab[token] = index\n",
        "    return vocab\n",
        "\n",
        "class Atomwise_Tokenizer(object):\n",
        "    \"\"\"Run atom-level SMILES tokenization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Constructs a atom-level Tokenizer.\n",
        "        \"\"\"\n",
        "        # self.regex_pattern = r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "        self.regex_pattern = r\"(\\([^\\(\\)]{0,4}\\)|\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/\\/?|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "\n",
        "        self.regex = re.compile(self.regex_pattern)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\" Basic Tokenization of a SMILES.\n",
        "        \"\"\"\n",
        "        tokens = [token for token in self.regex.findall(text)]\n",
        "        return tokens\n",
        "\n",
        "class SMILES_SPE_Tokenizer(PreTrainedTokenizer):\n",
        "    r\"\"\"\n",
        "    Constructs a SMILES tokenizer. Based on SMILES Pair Encoding (https://github.com/XinhaoLi74/SmilesPE).\n",
        "    This tokenizer inherits from :class:`~transformers.PreTrainedTokenizer` which contains most of the methods. Users\n",
        "    should refer to the superclass for more information regarding methods.\n",
        "    Args:\n",
        "        vocab_file (:obj:`string`):\n",
        "            File containing the vocabulary.\n",
        "        spe_file (:obj:`string`):\n",
        "            File containing the trained SMILES Pair Encoding vocabulary.\n",
        "        unk_token (:obj:`string`, `optional`, defaults to \"[UNK]\"):\n",
        "            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
        "            token instead.\n",
        "        sep_token (:obj:`string`, `optional`, defaults to \"[SEP]\"):\n",
        "            The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
        "            for sequence classification or for a text and a question for question answering.\n",
        "            It is also used as the last token of a sequence built with special tokens.\n",
        "        pad_token (:obj:`string`, `optional`, defaults to \"[PAD]\"):\n",
        "            The token used for padding, for example when batching sequences of different lengths.\n",
        "        cls_token (:obj:`string`, `optional`, defaults to \"[CLS]\"):\n",
        "            The classifier token which is used when doing sequence classification (classification of the whole\n",
        "            sequence instead of per-token classification). It is the first token of the sequence when built with\n",
        "            special tokens.\n",
        "        mask_token (:obj:`string`, `optional`, defaults to \"[MASK]\"):\n",
        "            The token used for masking values. This is the token used when training this model with masked language\n",
        "            modeling. This is the token which the model will try to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_file, spe_file,\n",
        "                unk_token=\"[UNK]\",\n",
        "                sep_token=\"[SEP]\",\n",
        "                pad_token=\"[PAD]\",\n",
        "                cls_token=\"[CLS]\",\n",
        "                mask_token=\"[MASK]\",\n",
        "                **kwargs):\n",
        "        if not os.path.isfile(vocab_file):\n",
        "            raise ValueError(\"Can't find a vocabulary file at path '{}'.\".format(vocab_file))\n",
        "        if not os.path.isfile(spe_file):\n",
        "            raise ValueError(\"Can't find a SPE vocabulary file at path '{}'.\".format(spe_file))\n",
        "\n",
        "        self.vocab = load_vocab(vocab_file)\n",
        "        self.spe_vocab = open(spe_file, 'r', encoding='utf-8')\n",
        "        self.ids_to_tokens = collections.OrderedDict([(ids, tok) for tok, ids in self.vocab.items()])\n",
        "        self.spe_tokenizer = SPE_Tokenizer(self.spe_vocab)\n",
        "\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.vocab, **self.added_tokens_encoder)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return self.spe_tokenizer.tokenize(text).split(' ')\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        return self.vocab.get(token, self.vocab.get(self.unk_token))\n",
        "\n",
        "    def decode(self, token_ids, skip_special_tokens=False, clean_up_tokenization_spaces=True):\n",
        "        text = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)\n",
        "        return self.convert_tokens_to_string(text)\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        return self.ids_to_tokens.get(index, self.unk_token)\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\n",
        "        out_string = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A BERT sequence has the following format:\n",
        "        - single sequence: ``[CLS] X [SEP]``\n",
        "        - pair of sequences: ``[CLS] A [SEP] B [SEP]``\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of IDs to which the special tokens will be added\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: list of `input IDs <../glossary.html#input-ids>`__ with the appropriate special tokens.\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` method.\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "            already_has_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
        "                Set to True if the token list is already formatted with special tokens for the model\n",
        "        Returns:\n",
        "            :obj:`List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        ::\n",
        "            0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
        "            | first sequence    | second sequence |\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: List of `token type IDs <../glossary.html#token-type-ids>`_ according to the given\n",
        "            sequence(s).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, vocab_path):\n",
        "        \"\"\"\n",
        "        Save the sentencepiece vocabulary (copy original file) and special tokens file to a directory.\n",
        "        Args:\n",
        "            vocab_path (:obj:`str`):\n",
        "                The directory in which to save the vocabulary.\n",
        "        Returns:\n",
        "            :obj:`Tuple(str)`: Paths to the files saved.\n",
        "        \"\"\"\n",
        "        index = 0\n",
        "        if os.path.isdir(vocab_path):\n",
        "            vocab_file = os.path.join(vocab_path, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "        else:\n",
        "            vocab_file = vocab_path\n",
        "        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.vocab.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(vocab_file)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "        return (vocab_file,)\n",
        "\n",
        "class SMILES_Atomwise_Tokenizer(PreTrainedTokenizer):\n",
        "    r\"\"\"\n",
        "    Constructs a SMILES tokenizer. Based on SMILES Pair Encoding (https://github.com/XinhaoLi74/SmilesPE).\n",
        "    This tokenizer inherits from :class:`~transformers.PreTrainedTokenizer` which contains most of the methods. Users\n",
        "    should refer to the superclass for more information regarding methods.\n",
        "    Args:\n",
        "        vocab_file (:obj:`string`):\n",
        "            File containing the vocabulary.\n",
        "        unk_token (:obj:`string`, `optional`, defaults to \"[UNK]\"):\n",
        "            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
        "            token instead.\n",
        "        sep_token (:obj:`string`, `optional`, defaults to \"[SEP]\"):\n",
        "            The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
        "            for sequence classification or for a text and a question for question answering.\n",
        "            It is also used as the last token of a sequence built with special tokens.\n",
        "        pad_token (:obj:`string`, `optional`, defaults to \"[PAD]\"):\n",
        "            The token used for padding, for example when batching sequences of different lengths.\n",
        "        cls_token (:obj:`string`, `optional`, defaults to \"[CLS]\"):\n",
        "            The classifier token which is used when doing sequence classification (classification of the whole\n",
        "            sequence instead of per-token classification). It is the first token of the sequence when built with\n",
        "            special tokens.\n",
        "        mask_token (:obj:`string`, `optional`, defaults to \"[MASK]\"):\n",
        "            The token used for masking values. This is the token used when training this model with masked language\n",
        "            modeling. This is the token which the model will try to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        unk_token=\"[UNK]\",\n",
        "        sep_token=\"[SEP]\",\n",
        "        pad_token=\"[PAD]\",\n",
        "        cls_token=\"[CLS]\",\n",
        "        mask_token=\"[MASK]\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        if not os.path.isfile(vocab_file):\n",
        "            raise ValueError(\n",
        "                \"Can't find a vocabulary file at path '{}'.\".format(vocab_file)\n",
        "            )\n",
        "        self.vocab = load_vocab(vocab_file)\n",
        "        self.ids_to_tokens = collections.OrderedDict([(ids, tok) for tok, ids in self.vocab.items()])\n",
        "        self.tokenizer = Atomwise_Tokenizer()\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.vocab, **self.added_tokens_encoder)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return self.tokenizer.tokenize(text)\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        return self.vocab.get(token, self.vocab.get(self.unk_token))\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        return self.ids_to_tokens.get(index, self.unk_token)\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\n",
        "        out_string = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A BERT sequence has the following format:\n",
        "        - single sequence: ``[CLS] X [SEP]``\n",
        "        - pair of sequences: ``[CLS] A [SEP] B [SEP]``\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of IDs to which the special tokens will be added\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: list of `input IDs <../glossary.html#input-ids>`__ with the appropriate special tokens.\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` method.\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "            already_has_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
        "                Set to True if the token list is already formatted with special tokens for the model\n",
        "        Returns:\n",
        "            :obj:`List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        ::\n",
        "            0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
        "            | first sequence    | second sequence |\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: List of `token type IDs <../glossary.html#token-type-ids>`_ according to the given\n",
        "            sequence(s).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, vocab_path):\n",
        "        \"\"\"\n",
        "        Save the sentencepiece vocabulary (copy original file) and special tokens file to a directory.\n",
        "        Args:\n",
        "            vocab_path (:obj:`str`):\n",
        "                The directory in which to save the vocabulary.\n",
        "        Returns:\n",
        "            :obj:`Tuple(str)`: Paths to the files saved.\n",
        "        \"\"\"\n",
        "        index = 0\n",
        "        if os.path.isdir(vocab_path):\n",
        "            vocab_file = os.path.join(vocab_path, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "        else:\n",
        "            vocab_file = vocab_path\n",
        "        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.vocab.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(vocab_file)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "        return (vocab_file,)"
      ],
      "metadata": {
        "id": "kAe2r-jj4sio"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ],
      "metadata": {
        "id": "uqlr3R0uOQsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from SmilesPE.tokenizer import SPE_Tokenizer\n",
        "\n",
        "model_name = 'aaronfeller/PeptideCLM-23.4M-all'\n",
        "!gdown 1vEyJt-8RHHY48QsEf_7UFfP30kkkBwbi # tokenizer files\n",
        "!gdown 1qtCAUPOhfdF4TsCblBoGn-tKiO15s1Po\n",
        "\n",
        "tokenizer = SMILES_SPE_Tokenizer('new_vocab.txt', 'new_splits.txt')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37167a7c32e74b50a19898ae2ebaf9e7",
            "3b361ff818c44e509d4e56f682df7051",
            "d2f9ca6e09384bc9a0d68cc4b872e72d",
            "ea2db7f24aee41ec88facccb8f620db3",
            "6c4a16ec1110442e8f6c4d9c4797d80f",
            "cb5fc5a70a0142018febbae0bf50430e",
            "479a8821a0264da5b8d721863c8ab500",
            "c36b67bed1c8441aa6626002ef622090",
            "3052c02b67694a1694e6983b49214b32",
            "5dee781d1a824550b4d447cac93dddfd",
            "4b8e1f25281f4ca8a3fe6b3e1de3a538",
            "5cf47037ace9440094e73c356a5ab9cc",
            "0e6bcc0697ae412c9aab1bb0938dc72a",
            "34650e862d75435c83984c974f7738e5",
            "8ba2dc5284aa4cf9802b9e8716230af9",
            "97f54dde25934491b6a0f0331db16090",
            "ef268fd44f484c7da7cea2ab24a759c5",
            "a210242468b641c1912e5a45e81e7ccd",
            "69f58deb079a41ed8d12b0dc61a555d3",
            "2a83da9abeb34d499f4551a8220a3977",
            "52553d4ead424f15a4b47406b1f29519",
            "04e9e70348024ac3a0a7b87bf8827a93"
          ]
        },
        "id": "WHS9zdasavBN",
        "outputId": "4150d186-e014-4daa-ecd6-9d8f3c57adda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vEyJt-8RHHY48QsEf_7UFfP30kkkBwbi\n",
            "To: /content/new_vocab.txt\n",
            "100% 2.99k/2.99k [00:00<00:00, 8.97MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qtCAUPOhfdF4TsCblBoGn-tKiO15s1Po\n",
            "To: /content/new_splits.txt\n",
            "100% 716/716 [00:00<00:00, 1.99MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/573 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37167a7c32e74b50a19898ae2ebaf9e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/175M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cf47037ace9440094e73c356a5ab9cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RoFormerForSequenceClassification were not initialized from the model checkpoint at aaronfeller/PeptideCLM-23.4M-all and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RoFormerForSequenceClassification(\n",
              "  (roformer): RoFormerModel(\n",
              "    (embeddings): RoFormerEmbeddings(\n",
              "      (word_embeddings): Embedding(586, 768, padding_idx=0)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RoFormerEncoder(\n",
              "      (embed_positions): RoFormerSinusoidalPositionalEmbedding(768, 64)\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x RoFormerLayer(\n",
              "          (attention): RoFormerAttention(\n",
              "            (self): RoFormerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RoFormerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RoFormerIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RoFormerOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RoFormerClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tokenizer.encode(smiles.iloc[0].SMILES, return_tensors=\"pt\")\n",
        "smiles.iloc[0].SMILES"
      ],
      "metadata": {
        "id": "g1PxFmoSk2_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "178a7828-ab54-4674-87ba-c59a3fe98da4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CC[C@H](C)[C@@H]1NC(=O)[C@@H]2CCCN2C(=O)[C@@H](CC(C)C)OC(=O)CCNC(=O)[C@H](C)N(C)C(=O)[C@H](C(C)C)NC1=O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "id": "gIHg7O-Jk769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603071ea-c166-4570-c3be-d3a72bacc4d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2,  29, 487, 193,   8, 485,  13,  58, 207, 485,  14,  30,  58,  14,\n",
              "         207, 485, 193,  28, 193,   8, 194,  66, 207,  31, 207, 487, 193,   8,\n",
              "          58, 193,   8, 207, 487, 193, 193,   8, 194,  59,  13, 174,   3]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.get_vocab())"
      ],
      "metadata": {
        "id": "YIioclV5k9Ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506881af-4d64-4198-c9a1-ad77b2bbbaaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, '#': 5, '%': 6, '(': 7, ')': 8, '+': 9, '-': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, '=': 22, '@': 23, 'A': 24, 'B': 25, 'Br': 26, 'Brc': 27, 'C': 28, 'CC': 29, 'CCC': 30, 'CCN': 31, 'CCO': 32, 'CCS': 33, 'CCc': 34, 'CCn': 35, 'CN': 36, 'CNC': 37, 'CNc': 38, 'CO': 39, 'COC': 40, 'CON': 41, 'COc': 42, 'CS': 43, 'CSC': 44, 'CSS': 45, 'CSc': 46, 'Cc': 47, 'Cl': 48, 'Clc': 49, 'Cn': 50, 'F': 51, 'Fc': 52, 'H': 53, 'I': 54, 'K': 55, 'L': 56, 'M': 57, 'N': 58, 'NC': 59, 'NCC': 60, 'NCc': 61, 'NN': 62, 'NO': 63, 'Nc': 64, 'Nn': 65, 'O': 66, 'OC': 67, 'OCC': 68, 'OCO': 69, 'OCc': 70, 'ON': 71, 'OO': 72, 'Oc': 73, 'P': 74, 'R': 75, 'S': 76, 'SC': 77, 'SCC': 78, 'SCc': 79, 'SS': 80, 'Sc': 81, 'T': 82, 'X': 83, 'Z': 84, '[': 85, '\\\\\\\\': 86, '(/': 87, ']': 88, 'a': 89, 'b': 90, 'c': 91, 'cc': 92, 'ccc': 93, 'ccn': 94, 'cco': 95, 'ccs': 96, 'cn': 97, 'cnc': 98, 'cnn': 99, 'co': 100, 'coc': 101, 'cs': 102, 'csc': 103, 'csn': 104, 'e': 105, 'g': 106, 'i': 107, 'l': 108, 'n': 109, 'nc': 110, 'ncc': 111, 'ncn': 112, 'nco': 113, 'ncs': 114, 'nn': 115, 'nnc': 116, 'nnn': 117, 'no': 118, 'noc': 119, 'non': 120, 'ns': 121, 'nsc': 122, 'nsn': 123, 'o': 124, 'oc': 125, 'occ': 126, 'on': 127, 'p': 128, 'r': 129, 's': 130, 'sc': 131, 'scc': 132, 'scn': 133, 'sn': 134, 't': 135, 'c1': 136, 'c2': 137, 'c3': 138, 'c4': 139, 'c5': 140, 'c6': 141, 'c7': 142, 'c8': 143, 'c9': 144, 'n1': 145, 'n2': 146, 'n3': 147, 'n4': 148, 'n5': 149, 'n6': 150, 'n7': 151, 'n8': 152, 'n9': 153, 'O1': 154, 'O2': 155, 'O3': 156, 'O4': 157, 'O5': 158, 'O6': 159, 'O7': 160, 'O8': 161, 'O9': 162, '(c1': 163, '(c2': 164, 'c1)': 165, 'c2)': 166, '(n1': 167, '(n2': 168, 'n1)': 169, 'n2)': 170, '(O1': 171, '(O2': 172, 'O2)': 173, '=O': 174, '=C': 175, '=c': 176, '=N': 177, '=n': 178, '=CC': 179, '=CN': 180, '=Cc': 181, '=cc': 182, '=NC': 183, '=Nc': 184, '=nC': 185, '=nc': 186, '#C': 187, '#CC': 188, '#CN': 189, '#N': 190, '#NC': 191, '#NN': 192, '(C': 193, 'C)': 194, '(O': 195, 'O)': 196, '(N': 197, 'N)': 198, 'NP': 199, 'PN': 200, 'CP': 201, 'PC': 202, 'NS': 203, 'SN': 204, 'SP': 205, 'PS': 206, 'C(=O)': 207, '(/Br)': 208, '(/C#N)': 209, '(/C)': 210, '(/C=N)': 211, '(/C=O)': 212, '(/CBr)': 213, '(/CC)': 214, '(/CCC)': 215, '(/CCF)': 216, '(/CCN)': 217, '(/CCO)': 218, '(/CCl)': 219, '(/CI)': 220, '(/CN)': 221, '(/CO)': 222, '(/CS)': 223, '(/Cl)': 224, '(/F)': 225, '(/I)': 226, '(/N)': 227, '(/NC)': 228, '(/NCC)': 229, '(/NO)': 230, '(/O)': 231, '(/OC)': 232, '(/OCC)': 233, '(/S)': 234, '(/SC)': 235, '(=C)': 236, '(=C/C)': 237, '(=C/F)': 238, '(=C/I)': 239, '(=C/N)': 240, '(=C/O)': 241, '(=CBr)': 242, '(=CC)': 243, '(=CCF)': 244, '(=CCN)': 245, '(=CCO)': 246, '(=CCl)': 247, '(=CF)': 248, '(=CI)': 249, '(=CN)': 250, '(=CO)': 251, '(=C\\\\\\\\C)': 252, '(=C\\\\\\\\F)': 253, '(=C\\\\\\\\I)': 254, '(=C\\\\\\\\N)': 255, '(=C\\\\\\\\O)': 256, '(=N)': 257, '(=N/C)': 258, '(=N/N)': 259, '(=N/O)': 260, '(=NBr)': 261, '(=NC)': 262, '(=NCC)': 263, '(=NCl)': 264, '(=NN)': 265, '(=NO)': 266, '(=NOC)': 267, '(=N\\\\\\\\C)': 268, '(=N\\\\\\\\N)': 269, '(=N\\\\\\\\O)': 270, '(=O)': 271, '(=S)': 272, '(B)': 273, '(Br)': 274, '(C#C)': 275, '(C#CC)': 276, '(C#CI)': 277, '(C#CO)': 278, '(C#N)': 279, '(C#SN)': 280, '(C)': 281, '(C=C)': 282, '(C=CF)': 283, '(C=CI)': 284, '(C=N)': 285, '(C=NN)': 286, '(C=NO)': 287, '(C=O)': 288, '(C=S)': 289, '(CBr)': 290, '(CC#C)': 291, '(CC#N)': 292, '(CC)': 293, '(CC=C)': 294, '(CC=O)': 295, '(CCBr)': 296, '(CCC)': 297, '(CCCC)': 298, '(CCCF)': 299, '(CCCI)': 300, '(CCCN)': 301, '(CCCO)': 302, '(CCCS)': 303, '(CCCl)': 304, '(CCF)': 305, '(CCI)': 306, '(CCN)': 307, '(CCNC)': 308, '(CCNN)': 309, '(CCNO)': 310, '(CCO)': 311, '(CCOC)': 312, '(CCON)': 313, '(CCS)': 314, '(CCSC)': 315, '(CCl)': 316, '(CF)': 317, '(CI)': 318, '(CN)': 319, '(CN=O)': 320, '(CNC)': 321, '(CNCC)': 322, '(CNCO)': 323, '(CNN)': 324, '(CNNC)': 325, '(CNO)': 326, '(CNOC)': 327, '(CO)': 328, '(COC)': 329, '(COCC)': 330, '(COCI)': 331, '(COCN)': 332, '(COCO)': 333, '(COF)': 334, '(CON)': 335, '(COO)': 336, '(CS)': 337, '(CSC)': 338, '(CSCC)': 339, '(CSCF)': 340, '(CSO)': 341, '(Cl)': 342, '(F)': 343, '(I)': 344, '(N)': 345, '(N=N)': 346, '(N=NO)': 347, '(N=O)': 348, '(N=S)': 349, '(NBr)': 350, '(NC#N)': 351, '(NC)': 352, '(NC=N)': 353, '(NC=O)': 354, '(NC=S)': 355, '(NCBr)': 356, '(NCC)': 357, '(NCCC)': 358, '(NCCF)': 359, '(NCCN)': 360, '(NCCO)': 361, '(NCCS)': 362, '(NCCl)': 363, '(NCNC)': 364, '(NCO)': 365, '(NCS)': 366, '(NCl)': 367, '(NN)': 368, '(NN=O)': 369, '(NNC)': 370, '(NO)': 371, '(NOC)': 372, '(O)': 373, '(OC#N)': 374, '(OC)': 375, '(OC=C)': 376, '(OC=O)': 377, '(OC=S)': 378, '(OCBr)': 379, '(OCC)': 380, '(OCCC)': 381, '(OCCF)': 382, '(OCCI)': 383, '(OCCN)': 384, '(OCCO)': 385, '(OCCS)': 386, '(OCCl)': 387, '(OCF)': 388, '(OCI)': 389, '(OCO)': 390, '(OCOC)': 391, '(OCON)': 392, '(OCSC)': 393, '(OCl)': 394, '(OI)': 395, '(ON)': 396, '(OO)': 397, '(OOC)': 398, '(OOCC)': 399, '(OOSN)': 400, '(OSC)': 401, '(P)': 402, '(S)': 403, '(SC#N)': 404, '(SC)': 405, '(SCC)': 406, '(SCCC)': 407, '(SCCF)': 408, '(SCCN)': 409, '(SCCO)': 410, '(SCCS)': 411, '(SCCl)': 412, '(SCF)': 413, '(SCN)': 414, '(SCOC)': 415, '(SCSC)': 416, '(SCl)': 417, '(SI)': 418, '(SN)': 419, '(SN=O)': 420, '(SO)': 421, '(SOC)': 422, '(SOOO)': 423, '(SS)': 424, '(SSC)': 425, '(SSCC)': 426, '([At])': 427, '([O-])': 428, '([O])': 429, '([S-])': 430, '(\\\\\\\\Br)': 431, '(\\\\\\\\C#N)': 432, '(\\\\\\\\C)': 433, '(\\\\\\\\C=N)': 434, '(\\\\\\\\C=O)': 435, '(\\\\\\\\CBr)': 436, '(\\\\\\\\CC)': 437, '(\\\\\\\\CCC)': 438, '(\\\\\\\\CCO)': 439, '(\\\\\\\\CCl)': 440, '(\\\\\\\\CF)': 441, '(\\\\\\\\CN)': 442, '(\\\\\\\\CNC)': 443, '(\\\\\\\\CO)': 444, '(\\\\\\\\COC)': 445, '(\\\\\\\\Cl)': 446, '(\\\\\\\\F)': 447, '(\\\\\\\\I)': 448, '(\\\\\\\\N)': 449, '(\\\\\\\\NC)': 450, '(\\\\\\\\NCC)': 451, '(\\\\\\\\NN)': 452, '(\\\\\\\\NO)': 453, '(\\\\\\\\NOC)': 454, '(\\\\\\\\O)': 455, '(\\\\\\\\OC)': 456, '(\\\\\\\\OCC)': 457, '(\\\\\\\\ON)': 458, '(\\\\\\\\S)': 459, '(\\\\\\\\SC)': 460, '(\\\\\\\\SCC)': 461, '[Ag+]': 462, '[Ag-4]': 463, '[Ag]': 464, '[Al-3]': 465, '[Al]': 466, '[As+]': 467, '[AsH3]': 468, '[AsH]': 469, '[As]': 470, '[At]': 471, '[B-]': 472, '[B@-]': 473, '[B@@-]': 474, '[BH-]': 475, '[BH2-]': 476, '[BH3-]': 477, '[B]': 478, '[Ba]': 479, '[Br+2]': 480, '[BrH]': 481, '[Br]': 482, '[C+]': 483, '[C-]': 484, '[C@@H]': 485, '[C@@]': 486, '[C@H]': 487, '[C@]': 488, '[CH-]': 489, '[CH2]': 490, '[CH3]': 491, '[CH]': 492, '[C]': 493, '[CaH2]': 494, '[Ca]': 495, '[Cl+2]': 496, '[Cl+3]': 497, '[Cl+]': 498, '[Cs]': 499, '[FH]': 500, '[F]': 501, '[H]': 502, '[He]': 503, '[I+2]': 504, '[I+3]': 505, '[I+]': 506, '[IH]': 507, '[I]': 508, '[K]': 509, '[Kr]': 510, '[Li+]': 511, '[LiH]': 512, '[MgH2]': 513, '[Mg]': 514, '[N+]': 515, '[N-]': 516, '[N@+]': 517, '[N@@+]': 518, '[N@@]': 519, '[N@]': 520, '[NH+]': 521, '[NH-]': 522, '[NH2+]': 523, '[NH3]': 524, '[NH]': 525, '[N]': 526, '[Na]': 527, '[O+]': 528, '[O-]': 529, '[OH+]': 530, '[OH2]': 531, '[OH]': 532, '[O]': 533, '[P+]': 534, '[P@+]': 535, '[P@@+]': 536, '[P@@]': 537, '[P@]': 538, '[PH2]': 539, '[PH]': 540, '[P]': 541, '[Ra]': 542, '[Rb]': 543, '[S+]': 544, '[S-]': 545, '[S@+]': 546, '[S@@+]': 547, '[S@@]': 548, '[S@]': 549, '[SH+]': 550, '[SH2]': 551, '[SH]': 552, '[S]': 553, '[Se+]': 554, '[Se-2]': 555, '[SeH2]': 556, '[SeH]': 557, '[Se]': 558, '[Si@]': 559, '[SiH2]': 560, '[SiH]': 561, '[Si]': 562, '[SrH2]': 563, '[TeH]': 564, '[Te]': 565, '[Xe]': 566, '[Zn+2]': 567, '[Zn-2]': 568, '[Zn]': 569, '[b-]': 570, '[c+]': 571, '[c-]': 572, '[cH-]': 573, '[cH]': 574, '[c]': 575, '[n+]': 576, '[n-]': 577, '[nH]': 578, '[n]': 579, '[o+]': 580, '[s+]': 581, '[se+]': 582, '[se]': 583, '[te+]': 584, '[te]': 585}\n"
          ]
        }
      ]
    }
  ]
}