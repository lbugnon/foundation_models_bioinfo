{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyWjaHsFohac"
      },
      "source": [
        "# Data preprocessing\n",
        "This notebook have all the previous data preparation pipeline. It is not needed as intermediate data files are provided.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pfam domain dataset \n",
        "\n",
        "The starting point is Pfam v32 domains dataset, which are already cropped from the complete proteins. As there are more than 1M sequences, a smaller dataset will be created for quicker tests.\n",
        "\n",
        "Additional details and full dataset in https://github.com/sinc-lab/llm4pfam. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# download full dataset\n",
        "!gdown 1eLfQo-xSSrtFGgbp9ArPblQteiJwOtST #\n",
        "!tar -xvf data.tar.gz\n",
        "!rm data.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "DixnuZ10oQ7S",
        "outputId": "67281920-cfd9-4201-9686-2aa10046409f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sequences in the dataset: 1339083\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>sequence</th>\n",
              "      <th>part</th>\n",
              "      <th>family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L8GA85_PSED2/604-855</td>\n",
              "      <td>PNKIEHTIAWGRELFESYFVKPAETVNLYLSQPNYINTTLKQGGNE...</td>\n",
              "      <td>train</td>\n",
              "      <td>PF10585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R7FMX8_9CLOT/502-554</td>\n",
              "      <td>VIIVIIFGIFLTLVISKILSKTILKGMPSSMILELPPYRKPQFGKI...</td>\n",
              "      <td>train</td>\n",
              "      <td>PF07664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R5XBV6_9FIRM/8-110</td>\n",
              "      <td>SALGVIFAVTAVLSFCGKSANLIAGYNTASEEEKAKYDEKKLCNGL...</td>\n",
              "      <td>train</td>\n",
              "      <td>PF12650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q6LXX1_METMP/35-253</td>\n",
              "      <td>LTVGVCAQYPPTIYEENGNLAGFDFDLMNEIAKRMNLNTDFKIYNS...</td>\n",
              "      <td>train</td>\n",
              "      <td>PF00497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E3J1Y8_FRAIE/399-483</td>\n",
              "      <td>QVSVAVYNGSMTKGLASKVTTALVGKGFQATTAGNADALTYTTSRV...</td>\n",
              "      <td>train</td>\n",
              "      <td>PF13399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          sequence_name                                           sequence  \\\n",
              "0  L8GA85_PSED2/604-855  PNKIEHTIAWGRELFESYFVKPAETVNLYLSQPNYINTTLKQGGNE...   \n",
              "1  R7FMX8_9CLOT/502-554  VIIVIIFGIFLTLVISKILSKTILKGMPSSMILELPPYRKPQFGKI...   \n",
              "2    R5XBV6_9FIRM/8-110  SALGVIFAVTAVLSFCGKSANLIAGYNTASEEEKAKYDEKKLCNGL...   \n",
              "3   Q6LXX1_METMP/35-253  LTVGVCAQYPPTIYEENGNLAGFDFDLMNEIAKRMNLNTDFKIYNS...   \n",
              "4  E3J1Y8_FRAIE/399-483  QVSVAVYNGSMTKGLASKVTTALVGKGFQATTAGNADALTYTTSRV...   \n",
              "\n",
              "    part   family  \n",
              "0  train  PF10585  \n",
              "1  train  PF07664  \n",
              "2  train  PF12650  \n",
              "3  train  PF00497  \n",
              "4  train  PF13399  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def read_data(path):\n",
        "    shards = []\n",
        "    for fn in os.listdir(path):\n",
        "        with open(os.path.join(path, fn)) as f:\n",
        "            shards.append(pd.read_csv(f, index_col=None))\n",
        "    return pd.concat(shards)\n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "for part in [\"train\", \"dev\", \"test\"]:\n",
        "    df = read_data(f\"data/clustered/{part}/\")\n",
        "    df[\"part\"] = part\n",
        "    df[\"sequence_name\"] = df.sequence_name.replace(\"/\", \"-\")\n",
        "    df[\"family\"] = df[\"family_accession\"].str.split(\".\").str[0]\n",
        "    data.append(df.drop(columns=[\"family_id\", \"family_accession\", \"aligned_sequence\"]))\n",
        "\n",
        "data = pd.concat(data)\n",
        "!rm -r data/clustered/\n",
        "print(\"Number of sequences in the dataset:\", len(data))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TwOSTg0PpOm6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80211, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a subset of families from Pfam, reducing also the number of sequences.\n",
        "\n",
        "families = pd.read_csv(\"data/pfam_some_families.csv\")\n",
        "data = data[data.family.isin(families.PF)]\n",
        "data.set_index(\"sequence_name\", inplace=True)\n",
        "data.to_csv(\"data/pfam_some_sequences.csv\")\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get similarity within each family with blast\n",
        "\n",
        "Install instructions:\n",
        "\n",
        "    https://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/ or\n",
        "    sudo apt-get install ncbi-blast+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "!mkdir data/fam_dist\n",
        "!mkdir tmp\n",
        "for fam in data.family.unique():\n",
        "    with open(\"tmp/seqs.fasta\", \"w\") as f:\n",
        "        df = data[data.family==fam]\n",
        "        for k in range(len(df)):\n",
        "            f.write(f\">{df.iloc[k].name}\\n{df.iloc[k].sequence}\\n\")\n",
        "    !makeblastdb -in tmp/seqs.fasta -dbtype prot -out tmp/db\n",
        "    !blastp -query tmp/seqs.fasta -num_threads 8 -db tmp/db -out data/fam_dist/{fam}.txt -outfmt 6\n",
        "    !rm tmp/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_98tToJ8tdjW"
      },
      "source": [
        "## Computing embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBbU7lbLxtNE",
        "outputId": "c411a8b7-39a0-49f3-857c-115e42f896d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/lbugnon/.cache/torch/hub/facebookresearch_esm_main\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ESM2(\n",
              "  (embed_tokens): Embedding(33, 640, padding_idx=1)\n",
              "  (layers): ModuleList(\n",
              "    (0-29): 30 x TransformerLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (k_proj): Linear(in_features=640, out_features=640, bias=True)\n",
              "        (v_proj): Linear(in_features=640, out_features=640, bias=True)\n",
              "        (q_proj): Linear(in_features=640, out_features=640, bias=True)\n",
              "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
              "        (rot_emb): RotaryEmbedding()\n",
              "      )\n",
              "      (self_attn_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "      (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
              "      (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
              "      (final_layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (contact_head): ContactPredictionHead(\n",
              "    (regression): Linear(in_features=600, out_features=1, bias=True)\n",
              "    (activation): Sigmoid()\n",
              "  )\n",
              "  (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
              "    (layer_norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch as tr\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "MAX_LEN = 1022\n",
        "EMB_NAME = \"esm2_t30_150M_UR50D\"\n",
        "LAST_LAYER = 30\n",
        "\n",
        "#EMB_NAME = \"esm2_t33_650M_UR50D\"\n",
        "# LAST_LAYER = 33\n",
        "\n",
        "# https://github.com/facebookresearch/esm#available-models\n",
        "model, alphabet = tr.hub.load(\"facebookresearch/esm:main\",\n",
        "                              EMB_NAME)\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJEc6f0httGv",
        "outputId": "f1cc42a4-a2cb-4716-f796-67cad99a2563"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load sequence datasets\n",
        "df = pd.read_csv(\"data/pfam_some_sequences.csv\", index_col=\"sequence_name\")\n",
        "\n",
        "def get_embedding(seq, aggregate=False):\n",
        "    \"\"\"Recibe una secuencia, devuelve un tensor de MxL donde M es el tamaño\n",
        "    del embedding y L la longitud de la secuencia. Si aggregate=True, promedia\n",
        "    la representación a lo largo de la secuencia devolviendo un vector M\"\"\"\n",
        "\n",
        "    # Recorta el dominio si supera la capacidad del LLM\n",
        "    center = len(seq)//2\n",
        "    start = max(0, center - MAX_LEN//2)\n",
        "    end = min(len(seq), center + MAX_LEN//2)\n",
        "    seq = seq[start:end]\n",
        "\n",
        "    # Formato requerido por el tokenizador, se pueden procesar  por lotes\n",
        "    # en paralelo\n",
        "    x = [(0, seq)]\n",
        "\n",
        "    with tr.no_grad():\n",
        "        _, _, tokens = batch_converter(x)\n",
        "        emb = model(tokens.to(DEVICE), repr_layers=[LAST_LAYER],\n",
        "                    return_contacts=True\n",
        "                    )[\"representations\"][LAST_LAYER].detach().cpu().squeeze()\n",
        "    \n",
        "    emb = emb.permute(1,0) # [L, M] -> [M, L], por conveniencia mas adelante\n",
        "    emb = emb.half() # reduce memory usage\n",
        "\n",
        "    if aggregate:\n",
        "        emb = np.array(emb.mean(dim=1))\n",
        "\n",
        "    return emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgve0AkzXfJ"
      },
      "source": [
        "Now we process all the sequences (this can be more efficient with larger GPUs). The process takes about 1h."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "ab9ad92a3f584989a7689affedb188bd",
            "dd6a093d7fb541c5ba2f2fd970d5301a",
            "3b12686dbcf94dcf955ebf59aaaca3d3",
            "d2a96133583d4d3d8625131b5c11258a",
            "37cf6b57d6aa4285a5531d9278dca0e8",
            "1283ff99a24b490eba06fa042560f2d7",
            "b2e3296e39a94d5aa5f63103a3cda484",
            "45f4606af64647e5bc2fb9a867670cb3",
            "65767969294b4b2db7547981857419fd",
            "1b86b23a9ff4470aa04a13213be7352e",
            "77d4075ea0564da6a106a4beb70c7f9f"
          ]
        },
        "id": "tHIm-J1xu0yS",
        "outputId": "35aec23b-edc0-4114-a1af-2b42971f242e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: no se puede crear el directorio «embeddings»: El fichero ya existe\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b67936576fe4d36833ca902e208d145",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/80211 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "\n",
        "!mkdir embeddings\n",
        "\n",
        "embeddings =  {}\n",
        "for i in tqdm(range(len(df))):\n",
        "    seq_name = df.iloc[i].name\n",
        "    # get average embedding for the sequence\n",
        "    embeddings[seq_name] = get_embedding(df.iloc[i].sequence, aggregate=True) \n",
        "    \n",
        "pickle.dump(embeddings, open(f\"embeddings/{EMB_NAME}.pk\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AMPLIFY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# paper: https://www.biorxiv.org/content/10.1101/2024.06.20.599739v2.full.pdf\n",
        "import os\n",
        "!git clone https://github.com/chandar-lab/AMPLIFY.git\n",
        "os.chdir(\"AMPLIFY\")\n",
        "!pip install --editable .[dev] \n",
        "!python3 -m pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "#EMB_NAME = \"AMPLIFY_120M\"\n",
        "EMB_NAME = \"AMPLIFY_350M\"\n",
        "\n",
        "# Load AMPLIFY and tokenizer\n",
        "model = AutoModel.from_pretrained(f\"chandar-lab/{EMB_NAME}\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(f\"chandar-lab/{EMB_NAME}\", trust_remote_code=True)\n",
        "\n",
        "# Move the model to GPU (required due to Flash Attention)\n",
        "model = model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "import torch as tr \n",
        "import pandas as pd\n",
        "\n",
        "# load sequence datasets\n",
        "df = pd.read_csv(\"data/pfam_some_sequences.csv\", index_col=\"sequence_name\")\n",
        "\n",
        "def get_embedding(seq, aggregate=False):\n",
        "    \n",
        "    with tr.no_grad():\n",
        "        input = tokenizer.encode(seq, return_tensors=\"pt\")\n",
        "        input = input.to(\"cuda\")\n",
        "        output = model(input, output_hidden_states=True)\n",
        "        output = output.hidden_states[-1].squeeze().cpu() # [1, seq_len, 640]\n",
        "        if aggregate:\n",
        "            output = output.mean(dim=0).numpy() # average over all sequence tokens \n",
        " \n",
        "    return output\n",
        "\n",
        "embeddings =  {}\n",
        "for i in tqdm(range(len(df))):\n",
        "    seq_name = df.iloc[i].name\n",
        "    # get average embedding for the sequence\n",
        "    embeddings[seq_name] = get_embedding(df.iloc[i].sequence, aggregate=True) \n",
        "    \n",
        "    \n",
        "pickle.dump(embeddings, open(f\"embeddings/{EMB_NAME}.pk\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PeptideCLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RoFormerForSequenceClassification were not initialized from the model checkpoint at aaronfeller/PeptideCLM-23.4M-all and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#!pip install torch transformers datasets SmilesPE pandas\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peptideclm_tokenizer.tokenizer import SMILES_SPE_Tokenizer\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "model_name = 'aaronfeller/PeptideCLM-23.4M-all'\n",
        "tokenizer = SMILES_SPE_Tokenizer('peptideclm_tokenizer/new_vocab.txt', 'peptideclm_tokenizer/new_splits.txt')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model.to(DEVICE);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch as tr  \n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import pickle \n",
        "smiles = pd.read_csv(\"data/smiles_pampa.csv\")\n",
        "\n",
        "embeddings =  {}\n",
        "for k in tqdm(range(len(smiles))):\n",
        "    with tr.no_grad():\n",
        "        input = tokenizer.encode(smiles.iloc[k].SMILES, return_tensors=\"pt\")\n",
        "        input = input.to(DEVICE)\n",
        "        output = model(input, output_hidden_states=True).hidden_states[-1].squeeze().cpu()\n",
        "    # get average embedding for the sequence\n",
        "    embeddings[k] = output.mean(dim=0).numpy() \n",
        "    \n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tyWjaHsFohac"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "peptideclm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1283ff99a24b490eba06fa042560f2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b86b23a9ff4470aa04a13213be7352e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37cf6b57d6aa4285a5531d9278dca0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b12686dbcf94dcf955ebf59aaaca3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f4606af64647e5bc2fb9a867670cb3",
            "max": 80211,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65767969294b4b2db7547981857419fd",
            "value": 3
          }
        },
        "45f4606af64647e5bc2fb9a867670cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65767969294b4b2db7547981857419fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d4075ea0564da6a106a4beb70c7f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9ad92a3f584989a7689affedb188bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd6a093d7fb541c5ba2f2fd970d5301a",
              "IPY_MODEL_3b12686dbcf94dcf955ebf59aaaca3d3",
              "IPY_MODEL_d2a96133583d4d3d8625131b5c11258a"
            ],
            "layout": "IPY_MODEL_37cf6b57d6aa4285a5531d9278dca0e8"
          }
        },
        "b2e3296e39a94d5aa5f63103a3cda484": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2a96133583d4d3d8625131b5c11258a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b86b23a9ff4470aa04a13213be7352e",
            "placeholder": "​",
            "style": "IPY_MODEL_77d4075ea0564da6a106a4beb70c7f9f",
            "value": " 3/80211 [00:10&lt;62:40:28,  2.81s/it]"
          }
        },
        "dd6a093d7fb541c5ba2f2fd970d5301a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1283ff99a24b490eba06fa042560f2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e3296e39a94d5aa5f63103a3cda484",
            "value": "  0%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
